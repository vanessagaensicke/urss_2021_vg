{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Imports'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-608dfa172a8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mImports\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Imports'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from Imports import *\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target values (%MGS, binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f43529765885>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load target data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbenMGS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../Datasets/BenV2/BenV2MGS.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mbenMGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'MGS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbenMGS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbenMGS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'MGS'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "# Load target data\n",
    "benMGS = pickle.load(open('../../Datasets/BenV2/BenV2MGS.pkl','rb'))\n",
    "benMGS.columns = ['MGS']\n",
    "benMGS = binarize(benMGS,'MGS',60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove entries with missing descriptor data\n",
    "missing = ['i005','i006','i014','i015','i027','i028','i033','i083','i086','i059','i132','i136','i138','i137','i157','i158','i159','i183','i184','i185','i186','i187','i188','i189','i190','i191','i192','i194','i233','i234']\n",
    "for row in benMGS.itertuples():\n",
    "    if row.Index in missing:\n",
    "        benMGS.drop([row.Index],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'benMGS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c89152270f20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbenMGS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MGS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# For regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlabelsClf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbenMGS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# For classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'benMGS' is not defined"
     ]
    }
   ],
   "source": [
    "labels = benMGS['MGS'].values.reshape(-1,1) # For regression\n",
    "labelsClf = benMGS['Label'].values.reshape(-1,1) # For classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"Label\", data=benMGS, palette=\"Set3\")\n",
    "ax.set(xlabel='Active [1] or not [0]', ylabel='N. of counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xyz(filename): # filename -> full path!\n",
    "    global nat, sym, pos\n",
    "    f = open(filename, \"r\")\n",
    "    nat = int(f.readline())\n",
    "    sym=[]\n",
    "    pos=np.zeros((nat,3))\n",
    "    f.readline()\n",
    "    for i in range (0,nat):\n",
    "        line = f.readline()\n",
    "        line_s = line.split()\n",
    "        sym.append(line_s[0])\n",
    "        pos[[i],[0]]=float(line_s[1]); pos[[i],[1]]=float(line_s[2]); pos[[i],[2]]=float(line_s[3])\n",
    "    return(nat,sym,pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz={}\n",
    "counter=0\n",
    "for i in benMGS.index:\n",
    "    # filename=\"../../Datasets/BenV2/xyzFiles/OBabel/\"+i+\".xyz\" # converted from oBabel\n",
    "    filename=\"../../Datasets/BenV2/xyzFiles/DFT/\"+i+\".xyz\" # DFT optimised\n",
    "    read_xyz(filename)\n",
    "    xyz[counter]=i,benMGS.MGS[i],benMGS.Label[i],nat,sym,pos\n",
    "    counter=counter+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some info...\n",
    "* 0 -> name, e.g i001\n",
    "* 1 -> MGS\n",
    "* 2 -> Label [0] non active, [1] active\n",
    "* 3 -> N. of atoms in the molecule\n",
    "* 4 -> Atomic symbols. e.g. xyz[126][4][3] gets the atomic symbol of the fourth atom in molecule indexed 126\n",
    "* 5 -> Atomic positions. e.g. xyz[126][5][0][2] gets the z-coordinate of the first atom in molecule indexed 126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the smiles\n",
    "smiles = pd.read_csv('../../Datasets/BenV2/BenV2Smi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benMGS_sm=benMGS\n",
    "benMGS_sm['ID'] = benMGS.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliques = pickle.load(open('../../Datasets/BenV2/BenV2Clq.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliques['ID'] = cliques.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cliques = pd.merge(cliques, benMGS_sm, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cliques.drop(['ID', 'MGS', 'Label'], axis = 1, inplace=True)\n",
    "clq = np.array(df_cliques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smiles = pd.merge(smiles, benMGS_sm, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add H's and create mol objects from each SMILE\n",
    "from rdkit import Chem\n",
    "\n",
    "mol_h=[]\n",
    "\n",
    "for i in df_smiles['SMILES']:\n",
    "    mol=Chem.MolFromSmiles(i)\n",
    "    mol_h.append(Chem.AddHs(mol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "SDTR=[]\n",
    "for m in mol_h:\n",
    "    desc=[]\n",
    "    desc.append(Chem.Descriptors.ExactMolWt(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumLipinskiHBA(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumLipinskiHBD(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumRotatableBonds(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumHBD(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumHBA(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumHeteroatoms(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumAmideBonds(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcFractionCSP3(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumRings(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumAromaticRings(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumAliphaticRings(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumSaturatedRings(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumHeterocycles(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumAromaticHeterocycles(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumSaturatedHeterocycles(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumAliphaticHeterocycles(m))\n",
    "    desc.append(Chem.rdMolDescriptors.CalcNumSpiroAtoms(m))\n",
    "    SDTR.append(desc)\n",
    "SDTR_n=np.array(SDTR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = pickle.load(open('../../Datasets/BenV2/BenV2SymObabelOptRF.pkl','rb'))\n",
    "sfs['ID'] = sfs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sfs = pd.merge(sfs, benMGS_sm, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sfs.drop(['ID', 'MGS', 'Label'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = np.array(df_sfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quippy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quippy import descriptors\n",
    "import ase\n",
    "import ase.build\n",
    "from ase import Atoms\n",
    "from ase.visualize import view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOAP descriptor, Carbon, Oxygen and Hydrogen both taken as SOAP centers.\n",
    "# Basic line straight out from the tutorial\n",
    "desc = descriptors.Descriptor(\"soap cutoff=3 l_max=4 n_max=4 atom_sigma=0.5 n_Z=3 Z={1 6 8} n_species=3 species_Z={1 6 8}\")\n",
    "# average -> average over the densities, and THEN the rotational invariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soaps={}\n",
    "separator=''\n",
    "for i in xyz:\n",
    "    at_sym = str(separator.join(xyz[i][4]))\n",
    "    at_pos = np.array(xyz[i][5])\n",
    "    at = Atoms(at_sym, positions=at_pos)\n",
    "    #print(i,desc.sizes(at),desc.n_dim)\n",
    "    soaps[i]=desc.calc(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A rather silly descriptor: the average of each SOAP vector / molecule\n",
    "\n",
    "ave_soap=np.zeros(len(soaps[0]['data'][0])) # always the same dimensionality for each molecule\n",
    "silly_soap_D=np.zeros((len(soaps),len(soaps[0]['data'][0])))\n",
    "\n",
    "for j in range (0,len(soaps)):\n",
    "    n_soaps = len(soaps[j]['data'])\n",
    "    for i in range (0,n_soaps):\n",
    "        ave_soap=ave_soap+soaps[j]['data'][i]\n",
    "    ave_soap=ave_soap/float(i)\n",
    "    silly_soap_D[j]=ave_soap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target values...\n",
    "targets=np.zeros(len(soaps))\n",
    "for j in range (0,len(soaps)):\n",
    "    targets[j] = xyz[j][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HBonds (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb = smiles = pd.read_csv('../../Datasets/BenV2/BenV2Hbonds2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hb = pd.merge(hb, benMGS_sm, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hb.drop(['ID', 'MGS','Label'], axis = 1, inplace=True)\n",
    "# hbs = np.array(df_hb.drop).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbs=np.array(df_hb['Hbonds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K fold over the *whole* dataset\n",
    "\n",
    "Same splits across the different descriptors (ensured by a given value of ```random state```). ```n_splits``` determines the training/test sets ratio. Controversial choice, I guess, but with only 200 datapoints we can't play the training/validation/test game..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=20, shuffle=True, random_state=7654)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cliques\n",
    "Xt_clq=[] ; Xte_clq=[] ; yt=[] ; yte=[]; idx_t=[]; idx_te=[]\n",
    "\n",
    "for train_index, test_index in skf.split(clq,targets.ravel()):\n",
    "    Xt_clq.append(clq[train_index])\n",
    "    Xte_clq.append(clq[test_index])\n",
    "    yt.append(targets.ravel()[train_index])\n",
    "    yte.append(targets.ravel()[test_index])\n",
    "    idx_t.append(train_index)\n",
    "    idx_te.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard descriptors\n",
    "Xt_sds=[] ; Xte_sds=[]\n",
    "\n",
    "for train_index, test_index in skf.split(SDTR_n,targets.ravel()):\n",
    "    Xt_sds.append(SDTR_n[train_index])\n",
    "    Xte_sds.append(SDTR_n[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symmetry functions \n",
    "Xt_sfs=[] ; Xte_sfs=[]\n",
    "\n",
    "for train_index, test_index in skf.split(sf,targets.ravel()):\n",
    "    Xt_sfs.append(sf[train_index])\n",
    "    Xte_sfs.append(sf[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOAPs \n",
    "Xt_sop=[] ; Xte_sop=[]\n",
    "\n",
    "for train_index, test_index in skf.split(silly_soap_D,targets.ravel()):\n",
    "    Xt_sop.append(silly_soap_D[train_index])\n",
    "    Xte_sop.append(silly_soap_D[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HBs \n",
    "Xt_hb=[] ; Xte_hb=[]\n",
    "\n",
    "for train_index, test_index in skf.split(hbs,targets.ravel()):\n",
    "    Xt_hb.append(hbs[train_index])\n",
    "    Xte_hb.append(hbs[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit each model n_splits times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same model across the different splits and features\n",
    "params = {'max_features': 'log2', 'min_samples_leaf':15, 'n_estimators': 1000}\n",
    "clf=RandomForestClassifier(criterion='entropy',n_estimators=params['n_estimators'],max_features=params['max_features'],min_samples_leaf=params['min_samples_leaf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cliques\n",
    "prd_clq=[] ; exp=[] ; idx=[]\n",
    "for i,j,k,l,m in zip(Xt_clq,yt,Xte_clq,yte,idx_te):\n",
    "    clf.fit(i,j);\n",
    "    prd_clq.append(clf.predict(k))\n",
    "    exp.append(l)\n",
    "    idx.append(m)\n",
    "prd_clq_f = np.array(list(np.concatenate(prd_clq).flat))\n",
    "exp_f = np.array(list(np.concatenate(exp).flat))\n",
    "idx_f = np.array(list(np.concatenate(idx).flat))\n",
    "matthews_corrcoef(prd_clq_f,exp_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_clq = confusion_matrix(prd_clq_f,exp_f)\n",
    "plot_conf_mat(cm_clq,[\"Inactive\",\"Active\"],normalise=True,percent=True,label=True,stat=False,name=\"exampleCM.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard descriptors\n",
    "prd_sds=[]\n",
    "for i,j,k in zip(Xt_sds,yt,Xte_sds):\n",
    "    clf.fit(i,j);\n",
    "    prd_sds.append(clf.predict(k))\n",
    "prd_sds_f = np.array(list(np.concatenate(prd_sds).flat))\n",
    "matthews_corrcoef(prd_sds_f,exp_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_sds = confusion_matrix(prd_sds_f,exp_f)\n",
    "plot_conf_mat(cm_sds,[\"Inactive\",\"Active\"],normalise=True,percent=True,label=True,stat=False,name=\"exampleCM.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symmetry functions\n",
    "prd_sfs=[]\n",
    "for i,j,k in zip(Xt_sfs,yt,Xte_sfs):\n",
    "    clf.fit(i,j);\n",
    "    prd_sfs.append(clf.predict(k))\n",
    "prd_sfs_f = np.array(list(np.concatenate(prd_sfs).flat))\n",
    "matthews_corrcoef(prd_sfs_f,exp_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_sfs = confusion_matrix(prd_sfs_f,exp_f)\n",
    "plot_conf_mat(cm_sfs,[\"Inactive\",\"Active\"],normalise=True,percent=True,label=True,stat=False,name=\"exampleCM.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOAPs\n",
    "prd_sop=[]\n",
    "for i,j,k in zip(Xt_sop,yt,Xte_sop):\n",
    "    clf.fit(i,j);\n",
    "    prd_sop.append(clf.predict(k))\n",
    "prd_sop_f = np.array(list(np.concatenate(prd_sop).flat))\n",
    "matthews_corrcoef(prd_sop_f,exp_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_sop = confusion_matrix(prd_sop_f,exp_f)\n",
    "plot_conf_mat(cm_sop,[\"Inactive\",\"Active\"],normalise=True,percent=True,label=True,stat=False,name=\"exampleCM.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HBonds\n",
    "prd_hb=[]\n",
    "for i,j,k in zip(Xt_hb,yt,Xte_hb):\n",
    "    clf.fit(i.reshape(-1,1),j);\n",
    "    prd_hb.append(clf.predict(k.reshape(-1,1)))\n",
    "prd_hb_f = np.array(list(np.concatenate(prd_hb).flat))\n",
    "matthews_corrcoef(prd_hb_f,exp_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_hb = confusion_matrix(prd_hb_f,exp_f)\n",
    "plot_conf_mat(cm_hb,[\"Inactive\",\"Active\"],normalise=True,percent=True,label=True,stat=False,name=\"exampleCM.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = np.array([])\n",
    "votes = []\n",
    "\n",
    "for j,k,l in zip(prd_sds_f,prd_sfs_f,prd_sop_f):\n",
    "    max_vote=stats.mode(np.array((j,k,l)))\n",
    "    votes.append(np.asscalar(max_vote[1]))\n",
    "    final_pred = np.append(final_pred, max_vote[0])\n",
    "matthews_corrcoef(final_pred,exp_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_all = confusion_matrix(final_pred,exp_f)\n",
    "plot_conf_mat(cm_all,[\"Inactive\",\"Active\"],normalise=True,percent=True,label=True,stat=False,name=\"exampleCM.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "df_all = pd.DataFrame({'sds':prd_sds_f, 'sfs':prd_sfs_f, 'sop':prd_sop_f, 'all':final_pred, 'exp':exp_f})\n",
    "colors = ('paleturquoise', 'deeppink')\n",
    "fig, ax = plt.subplots(figsize=(10,40))\n",
    "cmap = LinearSegmentedColormap.from_list('Custom', colors, len(colors))\n",
    "ax = sns.heatmap(df_all, cmap=cmap, linewidths=0.1, linecolor='gray')\n",
    "    \n",
    "# Set the colorbar labels\n",
    "colorbar = ax.collections[0].colorbar\n",
    "colorbar.set_ticks([0.25,0.75])\n",
    "colorbar.set_ticklabels(['Inactive', 'Active'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru=[]\n",
    "for i,j in zip(final_pred,exp_f):\n",
    "    if (i == j):\n",
    "        tru.append(1) # True\n",
    "    else:\n",
    "        tru.append(0) # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_v=pd.DataFrame({'truth':tru, 'votes':votes})\n",
    "\n",
    "sure_true=0\n",
    "crazy_false=0\n",
    "\n",
    "for i,j in zip(df_all_v['truth'],df_all_v['votes']):\n",
    "    if (i == 1) and (j == 3):\n",
    "        sure_true=sure_true+1\n",
    "    if (i == 0) and (j == 3):\n",
    "        crazy_false=crazy_false+1    \n",
    "\n",
    "print(\"Correct predictions, 3/3 votes:\", sure_true)\n",
    "print(\"Incorrect predictions, 3/3 votes:\", crazy_false)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "URSS 2021 VG",
   "language": "python",
   "name": "user_2021_vg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
